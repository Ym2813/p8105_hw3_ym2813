p8105\_hw3\_ym2813
================
Anna Ma
10/15/2021

``` r
library(tidyverse)


theme_set(theme_minimal())

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_color_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

Load the data set

``` r
library(p8105.datasets)
data("instacart")
```

``` r
# Find the number of users. 
instacart %>% 
  select(user_id) %>% 
  n_distinct()
```

**Description:** This data set has 1384617 rows of 131209 users, and 15
columns. The rows represents the products from the orders, and the
variables includes information about the order, user,and the product.
Some of the key variables includes order\_id, product\_id, user\_id,
order\_number, order\_dow, product\_name, aisle, and department. For
example, the first observation from the data set gives the information
that this product, identified by product\_id 49302, is in order number
1, which was placed by the user with user id 112108. This is the first
product that the user added to the cart and it’s been ordered before,
since the variable “reordered” is 1. This is the 4th order of the user
from instacart and it was placed on the 4th day of the week at 10
o’clock. The last order by the same user was 9 days ago. More
specifically about this product, it is the Bulgarian yogurt from the
yogurt aisle, with aisle id 120 and the dairy eggs department, with
department id 16.

**How many aisles are there, and which aisles are the most items ordered
from?**

``` r
# The number of aisles
aisles_n = instacart %>% 
  select(aisle_id) %>% 
  n_distinct()

aisles_n 
```

    ## [1] 134

``` r
# Which aisles are the most items ordered from
aisle_most = instacart %>% 
  count(aisle,name = "aisle_sum") %>% #count aisles
  filter(aisle_sum == max(aisle_sum)) %>% # find the aisles with most count
  select(aisle)

aisle_most
```

    ## # A tibble: 1 × 1
    ##   aisle           
    ##   <chr>           
    ## 1 fresh vegetables

There are 134 aisles in total, the fresh vegetables aisle is the most
ordered from.

**Plot the number of items ordered in each aislewith more than 10000
items ordered.**

``` r
instacart %>% 
  count(aisle, name = "aisle_sum") %>% 
  filter(aisle_sum >= 10000) %>% 
  arrange(aisle_sum) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = forcats::fct_reorder(aisle, sort(aisle_sum))) %>% 
  ggplot(aes(x = aisle_sum, y = aisle)) +
  geom_point() +
  labs(
    title = "Number of Item Sold in each Aisle",
    x = "Number of Items Sold",
    y = "Aisle",
    caption = "Data from instacart")
```

![](p8105_hw3_ym2813_files/figure-gfm/unnamed-chunk-5-1.png)<!-- -->

Organized the aisles from the least of items ordered to the most ordered
so that the plot is more readable

**Table for the three most popular items in each of the aisles “baking
ingredients”, “dog food care”, and “packaged vegetables fruits”.**

``` r
instacart %>% 
  group_by(aisle) %>%
  filter(aisle %in% c("baking ingredients", "dog food care" ,
         "packaged vegetables fruits")) %>% 
  count(product_name, name = "n_times_ordered") %>% 
  arrange(desc(n_times_ordered)) %>% 
  slice(1:3) %>% # only keep the top 3 rows for each group
  knitr::kable()
```

| aisle                      | product\_name                                 | n\_times\_ordered |
|:---------------------------|:----------------------------------------------|------------------:|
| baking ingredients         | Light Brown Sugar                             |               499 |
| baking ingredients         | Pure Baking Soda                              |               387 |
| baking ingredients         | Cane Sugar                                    |               336 |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |                30 |
| dog food care              | Organix Chicken & Brown Rice Recipe           |                28 |
| dog food care              | Small Dog Biscuits                            |                26 |
| packaged vegetables fruits | Organic Baby Spinach                          |              9784 |
| packaged vegetables fruits | Organic Raspberries                           |              5546 |
| packaged vegetables fruits | Organic Blueberries                           |              4966 |

From this table, we can see that the top three most popular item in the
baking ingredients aisle is light brown sugar, ordered 499 times, pure
baking soda, ordered 387 time, and cane sugar, ordered 336 times.
Similarly, in the dog food care aisle, the top three most popular
product is snack sticks chicken and rice recipe dog treats, ordered 30
times, organix chicken and brown rice recipe, ordered 28 times, and
small dog biscuits, ordered 26 times. Lastly, the top three most popular
product in the packaged vegetables fruits asile is organic baby spinach,
ordered 9784 times, organic raspberries, ordered 5546 times, and organic
blueberries, ordered 4966 times.

**Table for the mean hour of the day at which Pink Lady Apples and
Coffee Ice Cream are ordered on each day of the week.**

``` r
instacart %>%
  filter(product_name %in% c("Pink Lady Apples","Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>%
  summarize(
    mean_hour = mean(order_hour_of_day)
  ) %>% 
  pivot_wider(
    names_from = "order_dow",
    values_from = "mean_hour"
  ) %>% 
  rename("Sunday" = "0", 
         "Monday" = "1", 
         "Tuesday" = "2", 
         "Wednesday" = "3",
         "Thursday" = "4",
         "Friday" = "5",
         "Saturday" = "6") %>% 
  knitr::kable()
```

    ## `summarise()` has grouped output by 'product_name'. You can override using the `.groups` argument.

| product\_name    |   Sunday |   Monday |  Tuesday | Wednesday | Thursday |   Friday | Saturday |
|:-----------------|---------:|---------:|---------:|----------:|---------:|---------:|---------:|
| Coffee Ice Cream | 13.77419 | 14.31579 | 15.38095 |  15.31818 | 15.21739 | 12.26316 | 13.83333 |
| Pink Lady Apples | 13.44118 | 11.36000 | 11.70213 |  14.25000 | 11.55172 | 12.78431 | 11.93750 |

This is the table showing the mean hour of the day at which Pink Lady
Apples and Coffee Ice Cream are ordered on each day of the week. As we
can see, the mean hour of the day that people order Pink Lady Apples and
Coffee Ice Cream is in the range of 11 o’clock to 14 o’clock. The mean
varies very slightly in each day of the week.

## Problem 2

Load the data

``` r
data("brfss_smart2010")
```

Formatting data with appropriate variable names;focusing on the “Overall
Health” topic, including only response ordered from “Poor” to
“Excellent”

``` r
brfss_df = 
  brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  rename(state = locationabbr, location = locationdesc) %>% 
  filter(topic == "Overall Health", 
         response %in% c("Excellent","Very good","Good","Fair","Poor")) %>% 
  mutate(
    response = factor(response),
    response = forcats::fct_relevel(response, c("Poor","Fair","Good","Very good","Excellent"))) %>% 
  arrange(response)
```

**In 2002, which states were observed at 7 or more locations? What about
in 2010?**

``` r
brfss_df %>% 
  filter(year == 2002) %>% 
  group_by(state) %>% 
  summarise(n_location_obs = n_distinct(location)) %>% 
  filter(n_location_obs >= 7)
```

    ## # A tibble: 6 × 2
    ##   state n_location_obs
    ##   <chr>          <int>
    ## 1 CT                 7
    ## 2 FL                 7
    ## 3 MA                 8
    ## 4 NC                 7
    ## 5 NJ                 8
    ## 6 PA                10

``` r
brfss_df %>% 
  filter(year == 2010) %>% 
  group_by(state) %>% 
  summarise(n_location_obs = n_distinct(location)) %>% 
  filter(n_location_obs >= 7)
```

    ## # A tibble: 14 × 2
    ##    state n_location_obs
    ##    <chr>          <int>
    ##  1 CA                12
    ##  2 CO                 7
    ##  3 FL                41
    ##  4 MA                 9
    ##  5 MD                12
    ##  6 NC                12
    ##  7 NE                10
    ##  8 NJ                19
    ##  9 NY                 9
    ## 10 OH                 8
    ## 11 PA                 7
    ## 12 SC                 7
    ## 13 TX                16
    ## 14 WA                10

In 2002, there are 6 states that were observed at 7 or more locations.
The names of the states are CT,FL,MA, NC, NJ, and PA. In 2010, there are
14 states that were observed at 7 or more locations. The names of those
states are CA, CO, FL, MA, MD, NC, NE, NJ, NY, OH, PA, SC, TX, WA.

**Construct a data set limited to Excellent responses, and contains,
year, state, and a variable that averages the data\_value across
locations within a state.**

``` r
mean_excellent_df = brfss_df %>% 
  filter(response == "Excellent") %>% 
  group_by(year,state) %>% 
  mutate(
    mean_data_value = mean(data_value, na.rm = TRUE)
  ) %>% 
  select(year, state, mean_data_value) %>% 
  distinct()
mean_excellent_df
```

    ## # A tibble: 443 × 3
    ## # Groups:   year, state [443]
    ##     year state mean_data_value
    ##    <int> <chr>           <dbl>
    ##  1  2010 AL               18.4
    ##  2  2010 AZ               21.6
    ##  3  2010 AR               25.4
    ##  4  2010 CA               23.9
    ##  5  2010 CO               25.4
    ##  6  2010 CT               24.2
    ##  7  2010 DE               20.3
    ##  8  2010 DC               26.1
    ##  9  2010 FL               19.6
    ## 10  2010 GA               23.1
    ## # … with 433 more rows

**“Spaghetti” plot for average value over time within a state.**

``` r
mean_excellent_df %>% 
  ggplot(aes(x = year, y = mean_data_value,color = state)) + 
  geom_line(aes(group = state)) 
```

![](p8105_hw3_ym2813_files/figure-gfm/unnamed-chunk-12-1.png)<!-- -->

**Two-panel plot showing, for the years 2006, and 2010, distribution of
data\_value for responses (“Poor” to “Excellent”) among locations in NY
State.**

``` r
brfss_df %>% 
  filter(state == "NY", year == 2006 | year == 2010) %>% 
  ggplot(aes(x = data_value, fill = response)) +
  geom_density(alpha = .5) + 
  facet_grid(. ~ year) +
  theme(legend.position = "bottom")
```

![](p8105_hw3_ym2813_files/figure-gfm/unnamed-chunk-13-1.png)<!-- -->

## Problem 3

Load, tidy, and otherwise wrangle the data

``` r
accel_df = read_csv("data_hw3/accel_data.csv") %>% 
  pivot_longer(
    "activity.1":"activity.1440",
    names_to = "minute_of_day",
    names_prefix = "activity.",
    values_to = "activity") %>%
  mutate(
    day_type = if_else(day %in% c("Saturday","Sunday"), "weekend","weekday"),
    week = as.integer(week),
    day_id = as.integer(day_id),
    minute_of_day = as.integer(minute_of_day)
          ) %>% 
  select(week,day_id,day, day_type,minute_of_day,activity)
```

    ## Rows: 35 Columns: 1443

    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr    (1): day
    ## dbl (1442): week, day_id, activity.1, activity.2, activity.3, activity.4, ac...

    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

This data set have 6 variables, including the week, day, day\_id, minute
of the day, day\_type, and activity value. The set has 50400
observations. Each observation is about the activity counts for a
specific minute from a 24-hour day and the information about that day,
including the week, day\_id, and whether it is a weekday or weekend.

**Aggregate across minutes to create a total activity variable for each
day, and create a table showing these totals.**

``` r
#accel_df %>% 
#  group_by(day_id) %>% 
#  summarize(total_activity = sum(activity)) %>% 
#  knitr::kable()

accel_df %>% 
  group_by(day_id) %>% 
mutate(
    total_activity = sum(activity)
  ) %>% 
  select(week,day_id, day, day_type, total_activity) %>% 
  distinct() %>% 
  knitr::kable()
```

| week | day\_id | day       | day\_type | total\_activity |
|-----:|--------:|:----------|:----------|----------------:|
|    1 |       1 | Friday    | weekday   |       480542.62 |
|    1 |       2 | Monday    | weekday   |        78828.07 |
|    1 |       3 | Saturday  | weekend   |       376254.00 |
|    1 |       4 | Sunday    | weekend   |       631105.00 |
|    1 |       5 | Thursday  | weekday   |       355923.64 |
|    1 |       6 | Tuesday   | weekday   |       307094.24 |
|    1 |       7 | Wednesday | weekday   |       340115.01 |
|    2 |       8 | Friday    | weekday   |       568839.00 |
|    2 |       9 | Monday    | weekday   |       295431.00 |
|    2 |      10 | Saturday  | weekend   |       607175.00 |
|    2 |      11 | Sunday    | weekend   |       422018.00 |
|    2 |      12 | Thursday  | weekday   |       474048.00 |
|    2 |      13 | Tuesday   | weekday   |       423245.00 |
|    2 |      14 | Wednesday | weekday   |       440962.00 |
|    3 |      15 | Friday    | weekday   |       467420.00 |
|    3 |      16 | Monday    | weekday   |       685910.00 |
|    3 |      17 | Saturday  | weekend   |       382928.00 |
|    3 |      18 | Sunday    | weekend   |       467052.00 |
|    3 |      19 | Thursday  | weekday   |       371230.00 |
|    3 |      20 | Tuesday   | weekday   |       381507.00 |
|    3 |      21 | Wednesday | weekday   |       468869.00 |
|    4 |      22 | Friday    | weekday   |       154049.00 |
|    4 |      23 | Monday    | weekday   |       409450.00 |
|    4 |      24 | Saturday  | weekend   |         1440.00 |
|    4 |      25 | Sunday    | weekend   |       260617.00 |
|    4 |      26 | Thursday  | weekday   |       340291.00 |
|    4 |      27 | Tuesday   | weekday   |       319568.00 |
|    4 |      28 | Wednesday | weekday   |       434460.00 |
|    5 |      29 | Friday    | weekday   |       620860.00 |
|    5 |      30 | Monday    | weekday   |       389080.00 |
|    5 |      31 | Saturday  | weekend   |         1440.00 |
|    5 |      32 | Sunday    | weekend   |       138421.00 |
|    5 |      33 | Thursday  | weekday   |       549658.00 |
|    5 |      34 | Tuesday   | weekday   |       367824.00 |
|    5 |      35 | Wednesday | weekday   |       445366.00 |

There’s no apparent trends. However, day 24 and day 31 only have a total
activity of 1440, meaning that activity is 1 per minute on those days.
This differs with the rest of the dataset significantly, indicating that
the data might have been recorded wrong.

**Single-panel plot for the 24-hour activity time courses for each day**

``` r
accel_df %>% 
  ggplot(aes(x = minute_of_day, y = activity, color = day)) + 
  geom_point(alpha = 0.5)
```

![](p8105_hw3_ym2813_files/figure-gfm/unnamed-chunk-16-1.png)<!-- -->

From the scatter plot we can see that activity for each day are
typically low around the 1st to 400 minute of the day. Then activity
would start to increase and vary each day. The most amount of activity
is done on Sunday around 400 and 700 minute, and on Friday around 1250
minute. To see and interpret the plot more easily, I will convert the
minute to the hour of the day and plot a smooth plot.

``` r
accel_df %>% 
  mutate(
    hour_of_day = minute_of_day %/% 60,
  ) %>% 
  group_by(day_id,hour_of_day) %>% 
  ggplot(aes(x = hour_of_day, y = activity, color = day)) +
  scale_x_continuous(
    breaks = c(0,4,8,12,16,20,24),
    labels = c("0","4","8","12","16","20","24"),
    limits = c(0,24)
  ) +
  geom_smooth(se = FALSE)
```

![](p8105_hw3_ym2813_files/figure-gfm/unnamed-chunk-17-1.png)<!-- -->

Similar to the founding in the scatter plot above, the smooth plot shows
that activity is low from 0am to 8am of the day. After that, activity
start to increase. The amount of activity between 8am to 12 am is the
most out of all days on Sunday. After 12am, activity stays steady for a
few hours. Then there’s an increase around 4 pm to 8pm each day.
Activity have a peak around 8pm to 9 pm for Friday. Mostly, activity
counts start to decrease after 8 pm or 9pm each day and remains
decreasing for the rest of the day.
