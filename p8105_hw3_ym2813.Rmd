---
title: "p8105_hw3_ym2813"
author: "Anna Ma"
date: "10/15/2021"
output: github_document
---

```{r}
library(tidyverse)
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_color_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```



## Problem 1

Load the data set 

```{r}
library(p8105.datasets)
data("instacart")
```

The goal is to do some exploration of this dataset. To that end, write a short description of the dataset, noting the size and structure of the data, describing some key variables, and giving illstrative examples of observations. 


```{r, eval = FALSE}
# Find the number of users. 
instacart %>% 
  select(user_id) %>% 
  n_distinct()
```

```{r}
instacart %>% filter(order_id == 1)
```

This data set has `r nrow(instacart)` rows of `r instacart %>% select(user_id) %>% n_distinct()` users, and `r ncol(instacart)` columns. The rows represents the products from the orders, and the variables includes information about the order, user,and the product. Some of the key variables includes order_id, product_id, user_id, order_number, order_dow, product_name, aisle, and department. For example, the first observation from the data set gives the information that this product, identified by product_id 49302, is in order number 1, which was placed by the user with user id 112108. This is the first product that the user added to the cart and it's been ordered before, since the variable "reordered" is 1. This is the 4th order of the user from instacart and it was placed on the 4th day of the week at 10 o'clock. The last order by the same user was 9 days ago. More specifically about this product, it is the Bulgarian yogurt from the yogurt aisle, with aisle id 120 and the dairy eggs department, with department id 16. 




Then, do or answer the following (commenting on the results of each):

How many aisles are there, and which aisles are the most items ordered from?

```{r}
# The number of aisles
aisles_n = instacart %>% 
  select(aisle_id) %>% 
  n_distinct()

aisles_n 

# Which aisles are the most items ordered from
aisle_most = instacart %>% 
  count(aisle,name = "aisle_sum") %>% #count aisles
  filter(aisle_sum == max(aisle_sum)) %>% # find the aisles with most count
  select(aisle)

aisle_most
```

There are `r aisles_n` aisles in total, the `r aisle_most` aisle is the most ordered from. 


Plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. 

```{r}
instacart %>% 
  count(aisle, name = "aisle_sum") %>% 
  filter(aisle_sum >= 10000) %>% 
  arrange(aisle_sum) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = forcats::fct_reorder(aisle, sort(aisle_sum))) %>% 
  ggplot(aes(x = aisle_sum, y = aisle)) +
  geom_point() +
  labs(
    title = "Number of Item Sold in each Aisle",
    x = "Number of Items Sold",
    y = "Aisle",
    caption = "Data from instacart")
```

I organized the aisles from the least of items ordered to the most ordered so that the plot is more readable 

Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. Include the number of times each item is ordered in your table.

```{r}
instacart %>% 
  group_by(aisle) %>%
  filter(aisle %in% c("baking ingredients", "dog food care" ,
         "packaged vegetables fruits")) %>% 
  count(product_name, name = "n_times_ordered") %>% 
  arrange(desc(n_times_ordered)) %>% 
  slice(1:3) %>% # only keep the top 3 rows for each group
  knitr::kable()
```

From this table, we can see that the top three most popular item in the baking ingredients aisle is light brown sugar, ordered 499 times, pure baking soda, ordered 387 time, and cane sugar, ordered 336 times. Similarly, in the dog food care aisle, the top three most popular product is snack sticks chicken and rice recipe dog treats, ordered 30 times, organix chicken and brown rice recipe, ordered 28 times, and small dog biscuits, ordered 26 times. Lastly, the top three most popular product in the packaged vegetables fruits asile is organic baby spinach, ordered 9784 times, organic raspberries, ordered 5546 times, and organic blueberries, ordered 4966 times. 


```{r}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples","Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>%
  summarize(
    mean_hour = mean(order_hour_of_day)
  ) %>% 
  pivot_wider(
    names_from = "order_dow",
    values_from = "mean_hour"
  ) %>% 
  rename("Sunday" = "0", 
         "Monday" = "1", 
         "Tuesday" = "2", 
         "Wednesday" = "3",
         "Thursday" = "4",
         "Friday" = "5",
         "Saturday" = "6") %>% 
  knitr::kable()
```

This is the table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week. As we can see, the mean hour of the day that people order Pink Lady Apples and Coffee Ice Cream is in the range of 11 o'clock to 14 o'clock. The mean varies very slightly in each day of the week. 


## Problem 2

Load the data
```{r}
data("brfss_smart2010")
```


# format the data to use appropriate variable names;

Focusing on the "Overall Health" topic, including response ordered from "Poor" to "Excellent"

```{r}
brfss_df = 
  brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  rename(state = locationabbr, location = locationdesc) %>% 
  filter(topic == "Overall Health", 
         response %in% c("Excellent","Very good","Good","Fair","Poor")) %>% 
  mutate(
    response = factor(response),
    response = forcats::fct_relevel(response, c("Poor","Fair","Good","Very good","Excellent")))
```


Using this dataset, do or answer the following (commenting on the results of each):

In 2002, which states were observed at 7 or more locations? What about in 2010?

```{r}
brfss_df %>% 
  filter(year == 2002) %>% 
  group_by(state) %>% 
  summarise(n_location_obs = n_distinct(location)) %>% 
  filter(n_location_obs >= 7)

brfss_df %>% 
  filter(year == 2010) %>% 
  group_by(state) %>% 
  summarise(n_location_obs = n_distinct(location)) %>% 
  filter(n_location_obs >= 7)
```

In 2002, there are 6 states that were observed at 7 or more locations. The names of the states are CT,FL,MA, NC, NJ, and PA. In 2010, there are 14 states that were observed at 7 or more locations. The names of those states are CA, CO, FL, MA, MD, NC, NE, NJ, NY, OH, PA, SC, TX, WA. 

```{r}
mean_excellent_df = brfss_df %>% 
  filter(response == "Excellent") %>% 
  group_by(year,state) %>% 
  mutate(
    mean_data_value = mean(data_value, na.rm = TRUE)
  ) %>% 
  select(year, state, mean_data_value) %>% 
  distinct()
```

Construct a dataset that is limited to Excellent responses, and contains, year, state, and a variable that averages the data_value across locations within a state. 

```{r}
mean_excellent_df %>% 
  ggplot(aes(x = year, y = mean_data_value,color = state)) + 
  geom_line(aes(group = state)) 
```


Make a “spaghetti” plot of this average value over time within a state (that is, make a plot showing a line for each state across years – the geom_line geometry and group aesthetic will help).


Make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State.

